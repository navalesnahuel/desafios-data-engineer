# Proyecto de Data Engineering

En este proyecto, aprender√°s a realizar web scraping en la web de Mercadolibre, cargar los datos en un S3 creado con **MinIO** y luego, utilizando las funcionalidades de **Spark**, **Delta Lake** y **Airflow**, nos encargaremos de transformar, orquestar y gestionar los datos. Finalmente, emplearemos **Tableau** para crear un dashboard que muestre los resultados obtenidos.

El objetivo principal de este proyecto es abordar desaf√≠os comunes en el rol de Data Engineer utilizando las tecnolog√≠as m√°s avanzadas y pr√°cticas disponibles en el √°mbito de los datos, todo dentro de un entorno Dockerizado.

Adem√°s, quiero aclarar que dentro del mismo contenedor de Docker, est√°n incluidos servicios como **Jupyter Notebook** o **Hive** (para la creaci√≥n de Metastore). Estos nos pueden llegar a ser √∫tiles si queremos realizar an√°lisis m√°s profundos con los datos obtenidos.

![Servicios Usados](/img/apps.png)

## Qu√© estamos construyendo y por qu√©?

La idea es construir un Lake House que contenga los datos de las principales marcas de celulares ofrecidos en Mercadolibre, preparados en formato medallion para ser utilizados en herramientas de visualizaci√≥n de la manera m√°s eficiente posible. La pipeline se ejecutar√° diariamente para obtener actualizaciones de precios y poder rastrear cambios.

**¬øPor qu√© este proyecto?** Siempre que entro en Mercadolibre, me encuentro con precios diferentes o precios cuya variaci√≥n no es clara. Por eso, quise desarrollar una aplicaci√≥n que permita conocer el √∫ltimo precio de un celular y si ha subido, bajado o se ha mantenido desde la √∫ltima ejecuci√≥n de la pipeline. Este proyecto es un ejemplo genuino que incluye una gran cantidad de desaf√≠os t√≠picos de un Data Engineer.

**¬øQu√© vamos a hacer?** Empezaremos con el web scraping, que nos permitir√° tratar cualquier p√°gina web como una base de datos. Los datos extra√≠dos se cargar√°n y almacenar√°n en nuestro S3 en la secci√≥n de Raw Data. A continuaci√≥n, transformaremos y limpiaremos los datos para que sean utilizables mediante Spark. Con la ayuda de Delta Lake, fusionaremos la informaci√≥n para obtener las √∫ltimas actualizaciones de precios. Todo este proceso ser√° orquestado por Airflow y se ejecutar√° en cualquier entorno utilizando Docker.

![Diagrama](/img/diagrama.png)

### Obteniendo la data - Scrapeando

Internet est√° lleno de una infinidad de informaci√≥n, por lo que al hacer scraping, es crucial identificar qu√© datos son valiosos y cu√°les no lo son.

Para realizar un buen scraping en Python, hay dos librer√≠as clave: Scrapy y BeautifulSoup. En este proyecto, prefer√≠ utilizar Scrapy por su comodidad y capacidad para manejar grandes vol√∫menes de datos de manera eficiente.

Para encontrar los elementos exactos que necesitamos extraer, usamos las herramientas de desarrollo del navegador. Presionando `F12` en la p√°gina de Mercadolibre, podemos inspeccionar el HTML y encontrar los selectores necesarios.

Esta t√©cnica es esencial para identificar los selectores exactos que necesitamos en nuestros `XPath` para Scrapy. Con estas herramientas y t√©cnicas, vas a poder extraer una gran cantidad de datos valiosos de la web de manera eficiente y estructurada.

### Almacenando en S3-MinIO

Una vez que tenemos establecida la conexi√≥n con MinIO, subir los datos scrapeados a nuestro almacenamiento S3 es un proceso f√°cil.

![Configuracion Spark-Minio](/img/config.png)

Con un c√≥digo simple, podemos cargar los datos en el almacenamiento:

![Carga de Datos](/img/create_df.png)

### A√±adiendo Funcionalidades de Base de Datos a S3 ‚Äì Delta Lake y Spark

Para incorporar funcionalidades similares a las de una base de datos en tus archivos almacenados en S3, puedes crear una tabla Delta. Delta Lake facilita la gesti√≥n de esquemas din√°micos, permitiendo agregar nuevas columnas de manera incremental sin necesidad de dividir las ingestas en un lago de datos o canalizaciones posteriores.

¬øC√≥mo crear o leer una tabla Delta? Se puede hacer f√°cilmente proporcionando el formato Delta:

![Carga de Datos en formato Delta](/img/delta_write.png)

Con Delta Lake, tambi√©n puedes realizar operaciones avanzadas como merges, permiti√©ndote combinar datos de manera eficiente:

![Fusion de datos](/img/merge.png)

Usando estas funcionalidades y aplicando la limpieza y transformaci√≥n de datos, podr√°s construir tu LakeHouse dentro de S3 con tablas Delta Lake.

### Orquestando con Airflow

Llegamos a la etapa final del proceso: la orquestaci√≥n. Aunque existen varios orquestadores disponibles, en este proyecto utilic√© Airflow. Con la creaci√≥n de un DAG (Directed Acyclic Graph), me encargu√© de gestionar y coordinar los trabajos para que se env√≠en al cl√∫ster de Spark, garantizando que toda la data sea procesada correctamente y almacenada en S3.

### Visualizando los Datos con Tableau

Ning√∫n proyecto est√° completo sin una visualizaci√≥n. Por eso, me tom√© el tiempo para crear un dashboard sencillo en Tableau que presenta algunas visualizaciones clave para materializar nuestro trabajo y facilitar la interpretaci√≥n de los datos.

![Dashboard](/img/dashboard.png)

### DevOps Engine - Docker

Finalmente, quiero destacar que todo el proyecto fue desarrollado utilizando Docker. El c√≥digo incluye un Makefile que proporciona los comandos necesarios para ejecutar toda la aplicaci√≥n en cualquier m√°quina que tenga Docker instalado.

Dentro del entorno Docker, tambi√©n est√°n disponibles los siguientes servicios:

- **Jupyter Notebooks**: Integrado con todos los servicios necesarios para realizar operaciones avanzadas con los datos.
- **Hive**: Utilizado como servicio de metastore.
- **PostgreSQL**: Para la gesti√≥n de datos relacionales.

Adem√°s de los servicios ya mencionados, como **Airflow**, **Spark** y **MinIO**.

## Conclusi√≥n

Para ser efectivo en el mundo de la ingenier√≠a de datos, es crucial ser pr√°ctico con una amplia variedad de herramientas. Espero haber proporcionado inspiraci√≥n para que puedas desarrollar tu propio proyecto de ingenier√≠a de datos.

Eso es todo por ahora. Si te gust√≥, ¬°me encantar√≠a que dejaras una estrella en el repositorio de GitHub! üòâ